
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Notebook 1: Estimating Rates &#8212; Bayesian Inference with PyMC</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Notebook 2: Making Predictions" href="02_predict.html" />
    <link rel="prev" title="Bayesian Inference with PyMC" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      <h1 class="site-logo" id="site-title">Bayesian Inference with PyMC</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Bayesian Inference with PyMC
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Notebook 1: Estimating Rates
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_predict.html">
   Notebook 2: Making Predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_proportion.html">
   Notebook 3: Estimating Proportions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_hierarchical.html">
   Notebook 4: Hierarchical Models
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/01_rate.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/AllenDowney/BayesianInferencePyMC"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/AllenDowney/BayesianInferencePyMC/master?urlpath=tree/01_rate.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hockey">
   Hockey
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-gamma-distribution">
   The gamma distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#making-a-model">
   Making a model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adding-to-the-model">
   Adding to the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-do-we-get-to-inference">
   When do we get to inference?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#two-teams">
   Two teams
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-of-superiority">
   Probability of superiority
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="notebook-1-estimating-rates">
<h1>Notebook 1: Estimating Rates<a class="headerlink" href="#notebook-1-estimating-rates" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://allendowney.github.io/BayesianInferencePyMC">Bayesian Inference with PyMC</a></p>
<p>Copyright 2021 Allen B. Downey</p>
<p>License: <a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If we&#39;re running on Colab, install PyMC and ArviZ</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">IN_COLAB</span> <span class="o">=</span> <span class="s1">&#39;google.colab&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span>

<span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="o">!</span>pip install pymc3
    <span class="o">!</span>pip install arviz
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyMC generates a FutureWarning we don&#39;t need to deal with yet</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>In this notebook, we’ll use the result of a hockey game to estimate the rate at which each team would score against the other, in the long run.
In the next notebook, we’ll use these estimates to make predictions.</p>
<p>This example is meant to be fun, and to take advantage of our intuition for things like games, but the methods we’ll see are useful for any application where we are interested in events that occur over time, like customers arriving at a store, or patients being diagnosed with a disease.</p>
<p>Many systems like this can be well modeled by a Poisson process, which is based on the assumption that events are random and equally likely to occur at any time.
Of course, this assumption is not always valid, but it is often good enough for modeling.</p>
<p>In the example of scoring in games like hockey and soccer (football), it turns out to be a pretty good model, <a class="reference external" href="https://arxiv.org/abs/1002.0797">according to this paper</a>.</p>
</div>
<div class="section" id="hockey">
<h2>Hockey<a class="headerlink" href="#hockey" title="Permalink to this headline">¶</a></h2>
<p>In a hockey game, let’s assume that each team has some long-term average scoring rate, <span class="math notranslate nohighlight">\(\mu\)</span>, in goals per game.</p>
<p>To get started, suppose that, for Team A versus Team B, <span class="math notranslate nohighlight">\(\mu\)</span> is somehow known to be 2.4 goals per game.
If these two teams played 100 games, we would expect Team A to score 2.4 goals per game, on average.</p>
<p>But in an particular game, they might score 2 or 3 goals, or more, or less.
Based on the assumptions of a Poisson process, it turns out, the distribution of goals scored is Poisson with parameter <code class="docutils literal notranslate"><span class="pre">mu=2.4</span></code>.</p>
<p>To see what that distribution looks like, I’ll generate a random sample and plot a histogram.
Normally I would use NumPy or SciPy to generate random values from a particular distribution, but since we’ll be using PyMC later, we’ll start using it now.
Here’s how.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>

<span class="n">mu</span> <span class="o">=</span> <span class="mf">2.4</span>
<span class="n">sample_poisson</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Poisson</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">sample_poisson</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.446
</pre></div>
</div>
</div>
</div>
<p>And here’s what the histogram looks like.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">plot_hist</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot a histogram of goals.</span>
<span class="sd">    </span>
<span class="sd">    sample: sequence of values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">legend</span><span class="p">(</span><span class="o">**</span><span class="n">options</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make a legend only if there are labels.&quot;&quot;&quot;</span>
    <span class="n">handles</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">get_legend_handles_labels</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="o">**</span><span class="n">options</span><span class="p">)</span>
        
<span class="k">def</span> <span class="nf">decorate_goals</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Probability&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decorate the axes.&quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of goals&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of goals scored&#39;</span><span class="p">)</span>
    <span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_hist</span><span class="p">(</span><span class="n">sample_poisson</span><span class="p">)</span>
<span class="n">decorate_goals</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_9_0.png" src="_images/01_rate_9_0.png" />
</div>
</div>
<p>If the average is 2.4, it is most common to score 1 or 2 goals, less common to score 3 or 4, less common to score 0, and rare to score more than 4.</p>
</div>
<div class="section" id="the-gamma-distribution">
<h2>The gamma distribution<a class="headerlink" href="#the-gamma-distribution" title="Permalink to this headline">¶</a></h2>
<p>In the previous section we assume that the goal scoring rate is known, but usually it’s something we have to estimate.
If we are not certain what the value of <code class="docutils literal notranslate"><span class="pre">mu</span></code> is, we can use a distribution to represent possible values and their relative likelihoods.</p>
<p>To represent this distribution, I will use a gamma distribution.
That’s not the only option, but the gamma distribution is a reasonable choice because:</p>
<ul class="simple">
<li><p>The values in a gamma distribution are continuous and non-negative, so that’s appropriate for representing a goal-scoring rate.</p></li>
<li><p>As we’ll see, the shape of the gamma distribution is consistent with what we know about goal scoring in games like hockey.</p></li>
</ul>
<p>The shape of the gamma distribution is controlled by two parameters, <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">beta</span></code>.
I’ll assign them values now, and at the end of the fourth notebook, we’ll see where they came from!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">4.6</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mf">1.9</span>
</pre></div>
</div>
</div>
</div>
<p>I’ll use PyMC again to draw a sample from this distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_gamma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Gamma</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And here’s what it looks like.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">plot_kde</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot a distribution using KDE.</span>
<span class="sd">    </span>
<span class="sd">    sample: sequence of values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">cut</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">decorate_rate</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Likelihood&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decorate the axes.&quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Goals per game (mu)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of goal scoring rate&#39;</span><span class="p">)</span>
    <span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_kde</span><span class="p">(</span><span class="n">sample_gamma</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;gamma&#39;</span><span class="p">)</span>
<span class="n">decorate_rate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_18_0.png" src="_images/01_rate_18_0.png" />
</div>
</div>
<p>This distribution represents possible goal-scoring rates for one team against another.
When the worst team plays the best team, their goal-scoring rate might be close to 0.
When the best team plays the worst, their goal-scoring rate might be 8 goals per game, or more.
But for most teams, we expect goal-scoring rates near 2.</p>
</div>
<div class="section" id="making-a-model">
<h2>Making a model<a class="headerlink" href="#making-a-model" title="Permalink to this headline">¶</a></h2>
<p>As we’ve seen, we can use PyMC to generate random values from a distribution.
But it is more common to use PyMC to create a <code class="docutils literal notranslate"><span class="pre">Model</span></code>, which is an object that represents random quantities and the relationships between them.</p>
<p>We’ll start with a model that contains only one random quantity, and work our way up.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_prior_predictive</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The first line creates an empty model.
The <code class="docutils literal notranslate"><span class="pre">with</span></code> statement creates a context so that the quantities we creates inside are added to the model.</p>
<p>This model contains a <code class="docutils literal notranslate"><span class="pre">Gamma</span></code> distribution with the name <code class="docutils literal notranslate"><span class="pre">mu</span></code> and the parameters <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">beta</span></code>.</p>
<p>Then it uses <code class="docutils literal notranslate"><span class="pre">sample_prior_predictive</span></code> to generate a sample from this distribution.
I’ll explain the name of this function soon.</p>
<p>The result is a “trace”, which is like a dictionary that maps from names to samples.
If we select the name <code class="docutils literal notranslate"><span class="pre">mu</span></code>, we get a sample from the gamma distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_prior</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">]</span>
<span class="n">sample_prior</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.4289891738366967
</pre></div>
</div>
</div>
</div>
<p>In this example, the gamma distribution is the prior distribution of <code class="docutils literal notranslate"><span class="pre">mu</span></code>; that is, it represents our knowledge of goal-scoring rates in general, rather than the goal-scoring rate of one team against another.</p>
<p>In other words, if we don’t know which two teams are playing, this distribution represents what we would believe about <code class="docutils literal notranslate"><span class="pre">mu</span></code>.
And here’s what it looks like.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_kde</span><span class="p">(</span><span class="n">sample_prior</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;prior&#39;</span><span class="p">)</span>
<span class="n">decorate_rate</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_25_0.png" src="_images/01_rate_25_0.png" />
</div>
</div>
<p>Other than random variation, it looks the same as the distribution we generated in the previous section.</p>
</div>
<div class="section" id="adding-to-the-model">
<h2>Adding to the model<a class="headerlink" href="#adding-to-the-model" title="Permalink to this headline">¶</a></h2>
<p>Again, a model represents random quantities and the connections between them.
So let’s add another quantity and a connection.</p>
<p>Here’s a model that represents the distribution of <code class="docutils literal notranslate"><span class="pre">mu</span></code> <em>and</em> the distribution of goals scored.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">goals</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="s1">&#39;goals&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_prior_predictive</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As in the previous model, <code class="docutils literal notranslate"><span class="pre">mu</span></code> is a goal-scoring rate drawn from a gamma distribution.
And now <code class="docutils literal notranslate"><span class="pre">goals</span></code> is the number of goals scored in a particular game, drawn from a Poisson distribution.</p>
<p>And, crucially, notice the connection between them: the parameter of the Poisson distribution is the value of <code class="docutils literal notranslate"><span class="pre">mu</span></code>drawn from the gamma distribution.</p>
<p>PyMC provides a function that represents a model as a graph that shows the connections between quantities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_30_0.svg" src="_images/01_rate_30_0.svg" /></div>
</div>
<p>Remember that <code class="docutils literal notranslate"><span class="pre">mu</span></code> is a rate in goals per game, and <code class="docutils literal notranslate"><span class="pre">goals</span></code> is an integer number of goals.</p>
<p>The distribution of <code class="docutils literal notranslate"><span class="pre">mu</span></code> from this model is the <strong>prior distribution</strong>, which we saw in the previous section.</p>
<p>The distribution of <code class="docutils literal notranslate"><span class="pre">goals</span></code> is the <strong>prior predictive distribution</strong>, because it represents the number of goals we would predict, based on the prior distribution of <code class="docutils literal notranslate"><span class="pre">mu</span></code>.</p>
<p>Let’s see what it looks like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_prior_pred</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;goals&#39;</span><span class="p">]</span>
<span class="n">sample_prior_pred</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.424
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_hist</span><span class="p">(</span><span class="n">sample_prior_pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;prior pred&#39;</span><span class="p">)</span>
<span class="n">decorate_goals</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_33_0.png" src="_images/01_rate_33_0.png" />
</div>
</div>
<p>The prior predictive distribution represents two sources of uncertainty:</p>
<ul class="simple">
<li><p>We are not sure what the goal-scoring rate, <code class="docutils literal notranslate"><span class="pre">mu</span></code>, is.</p></li>
<li><p>Even if we knew <code class="docutils literal notranslate"><span class="pre">mu</span></code>, we would not be sure how many goals would be scored in a particular game.</p></li>
</ul>
<p>Compared to the Poisson distribution we started with, with known <code class="docutils literal notranslate"><span class="pre">mu</span></code>, the mean of the prior predictive sample is about the same.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_poisson</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">sample_prior_pred</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2.446, 2.424)
</pre></div>
</div>
</div>
</div>
<p>But the standard deviation is bigger.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_poisson</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">sample_prior_pred</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1.5553404771946238, 1.8905618212584323)
</pre></div>
</div>
</div>
</div>
<p>The prior predictive distribution shows the distribution of goals we should expect in a game, based on the prior distribution only, not the data.</p>
<p>It is useful for model-checking, but it is also a step along the way to inference.</p>
</div>
<div class="section" id="when-do-we-get-to-inference">
<h2>When do we get to inference?<a class="headerlink" href="#when-do-we-get-to-inference" title="Permalink to this headline">¶</a></h2>
<p>So far, we have been modeling the system <em>forward</em>; that is, given the distributions and their parameters, we’ve been generating possible outcomes.</p>
<p>Now we’ll start running the model <em>backward</em>; given an actual outcome, we will estimate what the parameters might have been.
This process is called <strong>inference</strong>.</p>
<p>And here’s where we discover the power of PyMC.
Since we have already specified the model, we can use it for inference with just two changes:</p>
<ul class="simple">
<li><p>Instead of generating <code class="docutils literal notranslate"><span class="pre">goals</span></code>, we’ll mark goals as <code class="docutils literal notranslate"><span class="pre">observed</span></code> and provide the observed data.</p></li>
<li><p>And instead of calling <code class="docutils literal notranslate"><span class="pre">sample_prior_predictive</span></code>, we’ll call <code class="docutils literal notranslate"><span class="pre">sample</span></code>.</p></li>
</ul>
<p>For data, let’s assume that Team A plays Team B and scores 4 goals.
Here’s how we add it to the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">goals</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="s1">&#39;goals&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [mu]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [6000/6000 00:00<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 1 seconds.
</pre></div>
</div>
</div>
</div>
<p>The output provides information about how the sampling process worked.
The result is a <code class="docutils literal notranslate"><span class="pre">trace</span></code> object similar to the one from the last model.
The differences are:</p>
<ul class="simple">
<li><p>Since we provided observed data for <code class="docutils literal notranslate"><span class="pre">goals</span></code>, the trace does not contain a random sample of goals.</p></li>
<li><p>The values of <code class="docutils literal notranslate"><span class="pre">mu</span></code> in the trace are a sample from the <strong>posterior distribution</strong>, which represents what we believe about <code class="docutils literal notranslate"><span class="pre">mu</span></code> based on the data.</p></li>
</ul>
<p>We select the sample from the trace in the same way:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_posterior</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">]</span>
<span class="n">sample_posterior</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.993009030995
</pre></div>
</div>
</div>
</div>
<p>The mean of the posterior distribution is higher than the mean of the prior.
And here’s what it looks like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_kde</span><span class="p">(</span><span class="n">sample_prior</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Prior&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plot_kde</span><span class="p">(</span><span class="n">sample_posterior</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Posterior&#39;</span><span class="p">)</span>
<span class="n">decorate_rate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_45_0.png" src="_images/01_rate_45_0.png" />
</div>
</div>
<p>The mean of the prior distribution is about 2.4.
The team scored 4 goals, which is more than expected, so the posterior distribution is shifted to the right.</p>
<p>The mean of the posterior distribution is about 3, so it falls between the prior expectation and the observed outcome.</p>
<p>We can also use ArviZ to visualize the posterior distribution and compute summary statistics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>

<span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">sample_posterior</span><span class="p">)</span>
<span class="n">decorate_rate</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_47_0.png" src="_images/01_rate_47_0.png" />
</div>
</div>
<p>The 94% HDI is a <strong>credible interval</strong> that covers 94% of the posterior distribution. Based on the outcome of a single game, there is a 94% chance that the actual goal-scoring rate falls in this range (at least under the assumptions of the model).</p>
<p><strong>Exercise:</strong> The example we’ve run so far is based on three parameters: the values of <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">beta</span></code> that determine the prior distribution, and the observed number of goals.</p>
<p>Modify any of these variables and run the example again to see what effect they have.</p>
</div>
<div class="section" id="two-teams">
<h2>Two teams<a class="headerlink" href="#two-teams" title="Permalink to this headline">¶</a></h2>
<p>We can extend the model to estimate different values of <code class="docutils literal notranslate"><span class="pre">mu</span></code> for two teams.</p>
<p>As an example, suppose Team A scores 5 goals and Team B scores 1. The following model estimates their goal scoring rates against each other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">4.6</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mf">1.9</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">mu_A</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s1">&#39;mu_A&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">mu_B</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s1">&#39;mu_B&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">goals_A</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="s1">&#39;goals_A&#39;</span><span class="p">,</span> <span class="n">mu_A</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">goals_B</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="s1">&#39;goals_B&#39;</span><span class="p">,</span> <span class="n">mu_B</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s the graphical representation of this model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_54_0.svg" src="_images/01_rate_54_0.svg" /></div>
</div>
<p>And now we can run the sampler.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [mu_B, mu_A]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [6000/6000 00:01<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 1 seconds.
</pre></div>
</div>
</div>
</div>
<p>We can use <code class="docutils literal notranslate"><span class="pre">plot_trace</span></code> to review the results and do some visual diagnostics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_58_0.png" src="_images/01_rate_58_0.png" />
</div>
</div>
<p>There are two things to check for:</p>
<ul class="simple">
<li><p>Since each sampling chain is trying to sample from the same distribution, their results should be similar. If there are large deviations between them, that can be a sign of trouble.</p></li>
<li><p>The sequence of values should looks like random noise; if it looks like the sampler gets stuck for a while, that’s a sign of trouble, too.</p></li>
</ul>
<p>For this model, I expect the results to look pretty good.</p>
<p>Here are the posterior distribitions for <code class="docutils literal notranslate"><span class="pre">mu_B</span></code> and <code class="docutils literal notranslate"><span class="pre">mu_A</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu_A</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;mu_A&#39;</span><span class="p">]</span>
<span class="n">mu_B</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;mu_B&#39;</span><span class="p">]</span>
<span class="n">mu_B</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">mu_A</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1.95445465497946, 3.2912325706424594)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_kde</span><span class="p">(</span><span class="n">mu_A</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;mu_A posterior&#39;</span><span class="p">)</span>
<span class="n">plot_kde</span><span class="p">(</span><span class="n">mu_B</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;mu_B posterior&#39;</span><span class="p">)</span>
<span class="n">decorate_rate</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01_rate_61_0.png" src="_images/01_rate_61_0.png" />
</div>
</div>
</div>
<div class="section" id="probability-of-superiority">
<h2>Probability of superiority<a class="headerlink" href="#probability-of-superiority" title="Permalink to this headline">¶</a></h2>
<p>On the basis of one game, how confident should we be that Team A is the better team?
One way to answer this question is to compute the <strong>probability of superiority</strong>, which is the chance that a random value from the Team A posterior distribution exceeds a random value from the Team B posterior distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">mu_A</span> <span class="o">&gt;</span> <span class="n">mu_B</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8485
</pre></div>
</div>
</div>
</div>
<p>With a 5-1 result, we have some confidence that Team A is better, but it is not certain.</p>
<p><strong>Exercise:</strong> Suppose the same teams play again and Team A wins 3-1.
Modify the previous example to take into account both games. How much does the second game affect the posterior distributions and the probability of superiority?</p>
<p>Hint: The observed data can be a list.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Bayesian Inference with PyMC</a>
    <a class='right-next' id="next-link" href="02_predict.html" title="next page">Notebook 2: Making Predictions</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Allen B. Downey<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>