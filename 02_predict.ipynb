{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Making Predictions\n",
    "\n",
    "[Bayesian Inference with PyMC](https://allendowney.github.io/BayesianInferencePyMC)\n",
    "\n",
    "Copyright 2021 Allen B. Downey\n",
    "\n",
    "License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're running on Colab, install PyMC and ArviZ\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install pymc3\n",
    "    !pip install arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMC generates a FutureWarning we don't need to deal with yet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_hist(sample, **options):\n",
    "    \"\"\"Plot a histogram of goals.\n",
    "    \n",
    "    sample: sequence of values\n",
    "    \"\"\"\n",
    "    sns.histplot(sample, stat='probability', discrete=True,\n",
    "                 alpha=0.5, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def legend(**options):\n",
    "    \"\"\"Make a legend only if there are labels.\"\"\"\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    if len(labels):\n",
    "        plt.legend(**options)\n",
    "        \n",
    "def decorate_goals(ylabel='Probability'):\n",
    "    \"\"\"Decorate the axes.\"\"\"\n",
    "    plt.xlabel('Number of goals')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title('Distribution of goals scored')\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde(sample, **options):\n",
    "    \"\"\"Plot a distribution using KDE.\n",
    "    \n",
    "    sample: sequence of values\n",
    "    \"\"\"\n",
    "    sns.kdeplot(sample, cut=0, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_rate(ylabel='Likelihood'):\n",
    "    \"\"\"Decorate the axes.\"\"\"\n",
    "    plt.xlabel('Goals per game (mu)')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title('Distribution of goal scoring rate')\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "In the previous notebook, we defined a model with a goal-scoring rate drawn from a gamma distribution and a number of goals drawn from a Poisson distribution.\n",
    "\n",
    "We defined a prior distribution for the goal-scoring rate, `mu`, and computed the prior predictive distribution, which is the distribution of goals based on the prior distribution.\n",
    "\n",
    "Then we used PyMC to draw a sample from the posterior distribution, which is what we believe about `mu` based on observed data.\n",
    "And we used a two-team model to compute the probability of superiority, which is the chance that one team is better than another -- in the sense of having a higher goal-scoring rate -- based on an observed outcome.\n",
    "\n",
    "Now let's turn to the task of prediction; that is, given what we believe about `mu`, what distribution of goals should we expect if the same teams play again.\n",
    "From that we can compute the probability that each team would win a rematch.\n",
    "\n",
    "Here's the one-team model from the previous notebook, again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 4.6\n",
    "beta = 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as model1:\n",
    "    mu = pm.Gamma('mu', alpha, beta)\n",
    "    goals = pm.Poisson('goals', mu, observed=4)\n",
    "    trace1 = pm.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the posterior distribution of `mu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_posterior = trace1['mu']\n",
    "len(sample_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "az.plot_posterior(sample_posterior)\n",
    "decorate_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predictive distribution\n",
    "\n",
    "That tells us what we should believe about `mu` after we see the data, but it doesn't tell us how many goals we should expect in the future.\n",
    "For that, we need the **posterior predictive distribution**, which we can get by running `sample_posterior_predictive`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is similar to the trace we got from `sample`, but it contains a sample of `goals` rather than `mu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(sample_post_pred, label='posterior pred')\n",
    "decorate_goals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two teams\n",
    "\n",
    "Continuing the example from the previous notebook, suppose two teams have played each other  twice, Team A wins the first game 5-1 and the second game 3-1.\n",
    "The following model computes the posterior distribution for each team based on these outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model2:\n",
    "    mu_A = pm.Gamma('mu_A', alpha, beta)\n",
    "    mu_B = pm.Gamma('mu_B', alpha, beta)\n",
    "    goals_A = pm.Poisson('goals_A', mu_A, observed=[5,3])\n",
    "    goals_B = pm.Poisson('goals_B', mu_B, observed=[1,1])\n",
    "    trace2 = pm.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "with model2:\n",
    "    az.plot_trace(trace2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the posterior distributions for `mu_B` and `mu_A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_A = trace2['mu_A']\n",
    "mu_B = trace2['mu_B']\n",
    "mu_B.mean(), mu_A.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(mu_A, label='mu_A posterior')\n",
    "plot_kde(mu_B, label='mu_B posterior')\n",
    "decorate_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the probability of superiority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu_A > mu_B).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, we can be fairly confident that A is the better team, but that doesn't necessarily mean they will win the next game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "To compute the probability that A wins the next game, we can use `sample_posterior_predictive` to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    post_pred = pm.sample_posterior_predictive(trace2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction for each is an array, so I'll flatten it into a sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_A = post_pred['goals_A']\n",
    "goals_A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior predictive distributions of goals scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_A = post_pred['goals_A'].flatten()\n",
    "goals_B = post_pred['goals_B'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(goals_A, label='A')\n",
    "plot_hist(goals_B, color='C1', label='B')\n",
    "decorate_goals('PMF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team B is more likely than Team A to score 0, 1, or 2 goals.\n",
    "Team A is more likely to score 3 or more.\n",
    "\n",
    "Here's the chance that A wins the next game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chance that they lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the chance of a tie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sudden death\n",
    "\n",
    "In overtime, whichever team scores first wins. If we treat goal-scoring as a Poisson process, the time until the next goal is exponential with parameter `1/mu`.\n",
    "\n",
    "We can use the samples from the posterior distributions to generate samples from the posterior predictive distribution of time until the next goal, in units of games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, we expect it to take longer for Team B to score. But the game isn't decided by averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Compute the probability that Team A wins in overtime, then compute their total probability of winning the next game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus exercise:** What is their probability of winning at least 2 of the remaining 5 games in the series?\n",
    "\n",
    "Hint: Use `pm.Binomial.dist` to draw a sample of wins from a binomial distribution with `n=5` and `p=prob_win`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
