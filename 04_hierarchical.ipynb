{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Hierarchical Models\n",
    "\n",
    "[Bayesian Inference with PyMC](https://allendowney.github.io/BayesianInferencePyMC)\n",
    "\n",
    "Copyright 2021 Allen B. Downey\n",
    "\n",
    "License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're running on Colab, install PyMC and ArviZ\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install pymc3\n",
    "    !pip install arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMC generates a FutureWarning we don't need to deal with yet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_hist(sample, **options):\n",
    "    \"\"\"Plot a histogram of goals.\n",
    "    \n",
    "    sample: sequence of values\n",
    "    \"\"\"\n",
    "    sns.histplot(sample, stat='probability', discrete=True,\n",
    "                 alpha=0.5, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde(sample, **options):\n",
    "    \"\"\"Plot a distribution using KDE.\n",
    "    \n",
    "    sample: sequence of values\n",
    "    \"\"\"\n",
    "    sns.kdeplot(sample, cut=0, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def legend(**options):\n",
    "    \"\"\"Make a legend only if there are labels.\"\"\"\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    if len(labels):\n",
    "        plt.legend(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_heads(ylabel='Probability'):\n",
    "    \"\"\"Decorate the axes.\"\"\"\n",
    "    plt.xlabel('Number of heads (k)')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title('Distribution of heads')\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_proportion(ylabel='Likelihood'):\n",
    "    \"\"\"Decorate the axes.\"\"\"\n",
    "    plt.xlabel('Proportion of heads (x)')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title('Distribution of proportion')\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two coins\n",
    "\n",
    "In the previous notebook, we solved a version of the Euro problem, where we estimated the probability that a coin would come up heads.\n",
    "\n",
    "Now suppose instead of one coin, we have data from two coins.\n",
    "We spin each coin 250 times.\n",
    "The first one comes up heads 140 times, as in the previous example.\n",
    "The second one comes up heads 120 times.\n",
    "\n",
    "As we did in the hockey example, we can extend the model to estimate the proportion of heads for each coin separately.\n",
    "Here's a PyMC model that does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "n = 250\n",
    "with pm.Model() as model1:\n",
    "    x1 = pm.Beta('x1', alpha=2, beta=2)\n",
    "    x2 = pm.Beta('x2', alpha=2, beta=2)\n",
    "    k1 = pm.Binomial('k1', n=n, p=x1, observed=140)\n",
    "    k2 = pm.Binomial('k2', n=n, p=x2, observed=110)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the graphical representation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model1:\n",
    "    trace1 = pm.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior distributions for the two coins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "with model1:\n",
    "    az.plot_posterior(trace1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for the first coin are about the same as what we saw in the previous notebook. The results for the second coin are similar, but the center of the distribution is lower, because the observed value of `k` is smaller.\n",
    "\n",
    "This model is not exactly wrong, but it is not as right as it could be, because we are leaving some information on the table.\n",
    "\n",
    "That's because the data we have about each coin actually provides two kinds of information: it tells us about each coin individually, and it also tells us about coins in general.\n",
    "\n",
    "By estimating `x1` and `x2` separately, we are using the first kind of information, but not the second.\n",
    "\n",
    "An alternative is to use a **hierarchical model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going hierarchical\n",
    "\n",
    "In the previous model, the prior distribution is a beta distribution with values of `alpha` and `beta` that I chose with the intention of representing the information we have about coins and their probability of coming up heads.\n",
    "But my choice of these parameters was almost arbitrary.\n",
    "\n",
    "Instead of choosing these parameters ourselves, an alternative is to add them to the model and use the data to estimate them.\n",
    "\n",
    "Here's a version of the previous model where `alpha` and `beta` are values drawn from a gamma distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the graph for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is hierarchical because the variables can be arranged in layers.\n",
    "\n",
    "At the top level, `alpha` and `beta` are **hyperparameters** drawn from a two gamma distributions, which are called **hyperprior distributions**.\n",
    "\n",
    "At the next level, these hyperparameters are used to define the prior distributions of `x1` and `x2`.\n",
    "\n",
    "At the bottom level, these parameters are used to define the distributions of `k1` and `k2`, which are the observed values.\n",
    "\n",
    "Before we sample from the posterior distributions, let's look at the prior and prior predictive distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    trace2 = pm.sample_prior_predictive(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the distributions of the hyperparameters, `alpha` and `beta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(trace2['alpha'], label='alpha')\n",
    "plot_kde(trace2['beta'], label='beta')\n",
    "plt.xlabel('Hyperparameter')\n",
    "plt.xlabel('Likelihood')\n",
    "plt.title('Distribution of hyperparameters')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the prior distributions for `x1` and `x2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prior_x1 = trace2['x1']\n",
    "sample_prior_x2 = trace2['x2']\n",
    "sample_prior_x1.mean(), sample_prior_x2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(sample_prior_x1, color='gray', label='prior x1')\n",
    "plot_kde(sample_prior_x2, color='gray', label='prior x2')\n",
    "decorate_proportion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The priors for `x1` and `x2` are actually the same, but based on random samples, they look a little different.\n",
    "\n",
    "Now we're ready to sample from the posteriors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior distributions\n",
    "\n",
    "Let's run the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    trace2 = pm.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    az.plot_trace(trace2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior distributions for `x1` and `x2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    az.plot_posterior(trace2, var_names=['x1', 'x2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, they are not very different from what we got by estimating `x1` and `x2` separately.\n",
    "If we had less data, the hierarchical model would make more difference.\n",
    "\n",
    "But even if the distributions of the parameters are the same, the hierarchical model is different because the we have posterior distributions for the hyperparameters, `alpha` and `beta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    az.plot_posterior(trace2, var_names=['alpha', 'beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By themselves, they don't mean very much, but we can use them to generate a sample from a beta distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a distribution that represents what we believe about coins in general, based on the data from both coins.\n",
    "Here's what it looks like, compared to the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(sample_prior_x1, color='gray', label='prior')\n",
    "plot_kde(sample_posterior_x, label='posterior')\n",
    "decorate_proportion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior distribution is narrower than the posterior, which means we have more certainty about plausible values of `x`.\n",
    "Specifically, after seeing this data, we think values of `x` near 0.5 are more likely, and values at the extremes are less likely.\n",
    "\n",
    "In this example, we don't learn a lot about coins because we don't have a lot of data.\n",
    "So let's look at an example with more data, where we can see the utility of the hierarchical model more clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Attack Data\n",
    "\n",
    "This example is based on [Chapter 10 of *Probability and Bayesian Modeling*](https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#example-deaths-after-heart-attack); it uses data on death rates due to heart attack for patients treated at various hospitals in New York City.\n",
    "\n",
    "We can use Pandas to read the data into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename = 'DeathHeartAttackManhattan.csv'\n",
    "if not os.path.exists(filename):\n",
    "    !wget https://github.com/AllenDowney/BayesianInferencePyMC/raw/main/DeathHeartAttackManhattan.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns we need are `Cases`, which is the number of patients treated at each hospital, and `Deaths`, which is the number of those patients who died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ns = df['Cases'].values\n",
    "data_ks = df['Deaths'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a hierarchical model that estimates the death rate for each hospital, and simultaneously estimates the distribution of rates across hospitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model4:\n",
    "    az.plot_trace(trace4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior distributions for the hospitals. Notice that some of them are wider than others, because some hospitals treated more patients than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model4:\n",
    "    az.plot_posterior(trace4, var_names=['xs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior distributions for `alpha` and `beta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model4:\n",
    "    az.plot_posterior(trace4, var_names=['alpha', 'beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior distributions of the hyperparameters don't mean much by themselves, but we can use them to compute the posterior distribution of `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = trace4['alpha']\n",
    "betas = trace4['beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_posterior_x = pm.Beta.dist(alphas, betas).random()\n",
    "sample_posterior_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model4:\n",
    "    az.plot_posterior(sample_posterior_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution represents what we believe about the distribution of death rates across different hospitals, based on the data.\n",
    "\n",
    "NOTE: I used gamma distributions for the hyperparameters because they are simple, they work well with the PyMC sampler, and they are good enough for this example. But they are not the most common choice for a hierarchical beta-binomial model.\n",
    "[The chapter I got this example from](https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#example-deaths-after-heart-attack) has a good explanation of a more common way to parameterize this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson model\n",
    "\n",
    "Let's look at one more example of a hierarchical model, based on the hockey example we started with.\n",
    "\n",
    "Remember that we used a gamma distribution to represent the distribution of the rate parameters, `mu`.\n",
    "I chose the parameters of that distribution, `alpha` and `beta`, based on results from previous NHL playoff games.\n",
    "\n",
    "An alternative is to use a hierarchical model, where `alpha` and `beta` are hyperparameters.  Then we can use data to update estimate the distribution of `mu` for each team, and to estimate the distribution of `mu` across teams.\n",
    "\n",
    "Of course, now we need a prior distribution for `alpha` and `beta`.  A common choice is the half Cauchy distribution (see [Gelman](http://www.stat.columbia.edu/~gelman/research/published/taumain.pdf)), but on advice of counsel, I'm going with exponential.\n",
    "\n",
    "Here's a model that generates the prior distribution of `mu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prior_mu = trace5['mu']\n",
    "sample_prior_mu.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the prior distribution of `mu` looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_rate(ylabel='Density'):\n",
    "    \"\"\"Decorate the axes.\"\"\"\n",
    "    plt.xlabel('Goals per game (mu)')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title('Distribution of goal scoring rate')\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(sample_prior_mu)\n",
    "decorate_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a long-tailed distribution, with highest probability for values less than 100, but it admits the possibility that `mu` could be orders of magnitude bigger. Unreasonable as that might seem, it's probably what we want in a non-committal prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose a team plays one game and scores 4 goals.\n",
    "We can run the hierarchical model with this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model6:\n",
    "    trace6 = pm.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does not behave as well as the others. In particular, it is likely to \"diverge\" a few times during the sampling process.\n",
    "When we plot the trace, we see these divergences as gray lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model6:\n",
    "    az.plot_trace(trace6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ways to tune the sampler to reduce the number of divergences, but I won't bother because the visual diagnostics look fine.\n",
    "\n",
    "Here's the posterior distribution of `mu`.  The posterior mean is close to the observed value, which is what we expect with a weakly informative prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_post_mu = trace6['mu']\n",
    "sample_post_mu.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(sample_post_mu, label='mu posterior')\n",
    "decorate_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After one game, it seems like we have learned a lot about typical scoring rates in hockey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two teams\n",
    "\n",
    "Here's the hierarchical version of the model for two teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model7:\n",
    "    alpha = pm.Exponential('alpha', lam=1)\n",
    "    beta = pm.Exponential('beta', lam=1)\n",
    "    mu_A = pm.Gamma('mu_A', alpha, beta)\n",
    "    mu_B = pm.Gamma('mu_B', alpha, beta)\n",
    "    goals_A = pm.Poisson('goals_A', mu_A, observed=[5,3])\n",
    "    goals_B = pm.Poisson('goals_B', mu_B, observed=[1,1])\n",
    "    trace7 = pm.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `traceplot` to review the results and do some visual diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model7:\n",
    "    az.plot_trace(trace7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior distributions for the two teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_A = trace7['mu_A']\n",
    "mu_B = trace7['mu_B']\n",
    "mu_B.mean(), mu_A.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(mu_A, label='mu_A posterior')\n",
    "plot_kde(mu_B, label='mu_B posterior')\n",
    "decorate_rate('Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the probability that A is the better team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu_A > mu_B).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More background\n",
    "\n",
    "But let's take advantage of more information.  Here are the results from the most recent Stanley Cup finals.\n",
    "For games that went into overtime, I included only goals scored during regulation play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(BOS13 = [3, 1, 2, 5, 1, 2],\n",
    "            CHI13 = [3, 1, 0, 5, 3, 3],\n",
    "            NYR14 = [2, 4, 0, 2, 2],\n",
    "            LAK14 = [2, 4, 3, 1, 2],\n",
    "            TBL15 = [1, 4, 3, 1, 1, 0],\n",
    "            CHI15 = [2, 3, 2, 2, 2, 2],\n",
    "            SJS16 = [2, 1, 2, 1, 4, 1],\n",
    "            PIT16 = [3, 1, 2, 3, 2, 3],\n",
    "            NSH17 = [3, 1, 5, 4, 0, 0],\n",
    "            PIT17 = [5, 4, 1, 1, 6, 2],\n",
    "            VGK18 = [6, 2, 1, 2, 3],\n",
    "            WSH18 = [4, 3, 3, 6, 4],\n",
    "            STL19 = [2, 2, 2, 4, 2, 1, 4],\n",
    "            BOS19 = [4, 2, 7, 2, 1, 5, 1],\n",
    "            DAL20 = [4, 2, 2, 4, 2, 0],\n",
    "            TBL20 = [1, 3, 5, 4, 2, 2],\n",
    "            MTL21 = [1, 1, 3, 2, 0],\n",
    "            TBL21 = [5, 3, 6, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can get the data into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model8:\n",
    "    alpha = pm.Exponential('alpha', lam=1)\n",
    "    beta = pm.Exponential('beta', lam=1)\n",
    "    \n",
    "    mu = dict()\n",
    "    goals = dict()\n",
    "    for name, observed in data.items():\n",
    "        mu[name] = pm.Gamma('mu_'+name, alpha, beta)\n",
    "        goals[name] = pm.Poisson(name, mu[name], observed=observed)\n",
    "        \n",
    "    trace8 = pm.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with model8:\n",
    "    az.plot_trace(trace8, var_names=['alpha', 'beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior means for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_post_alpha = trace8['alpha']\n",
    "sample_post_alpha.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_post_beta = trace8['beta']\n",
    "sample_post_beta.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in case you were wondering how I chose the parameters of the gamma distribution in the first notebook.\n",
    "That's right -- time travel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_post_mu_TBL21 = trace8['mu_TBL21']\n",
    "sample_post_mu_MTL21 = trace8['mu_MTL21']\n",
    "sample_post_mu_TBL21.mean(), sample_post_mu_MTL21.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(sample_post_mu_TBL21, label='TBL21')\n",
    "plot_kde(sample_post_mu_MTL21, label='MTL21')\n",
    "decorate_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the updated chance that Tampa Bay is the better team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sample_post_mu_TBL21 > sample_post_mu_MTL21).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
